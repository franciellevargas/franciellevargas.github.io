   

<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>
Detecting Online Abuse and Harm in Latin America: Methods and Resources Towards Mitigating Racial Bias
</title>
<meta name="description" content="Research Scientist - Natural Language Processing">

    <!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class=" sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm sticky-top">
    <div class="container">
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
         
  <!-- 
 -->
                    
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     <span class="font-weight-bold">Detecting Online Abuse and Harm in Latin America: Methods and Resources Towards Mitigating Racial Bias </span>  
    </h1>
     <p> </p>
  </header>

  <article>
    <div class="profile float-right">
        <div class="address">
          <!-- <p>555 your office number</p> --> <!-- <p>123 your address street</p> --> <!-- <p>Your City, State 12345</p> -->
        </div>    
    </div>
    
    <div class="clearfix">
      <p align="justify"> 
        Language is often used to discriminate, attack and terrorize people. Moreover, through language which stereotypes and prejudices are 
         communicated and perpetuated <a href="https://aclanthology.org/2021.acl-long.149.pdf">(Field at al, 2021)</a>. Although the study on race and language is a relevant research topic, there is a significant
         lack of research concerning <b>Racist Language in Natural Language Processing</b>. To fill this important research gap, and due to severity of social 
         media abusive comments in Brazil and the lack of research in Portuguese, this ongoing research investigates and provides methods and resources 
         for racist hate speech detection for the Brazilian Portuguese language </a> 
      </p>

      <p align="justify">
         Furthermore, towards boosting equitable and inclusive technologies in South America, this research <b>providing methods and resources for Brazilian hate speech detection aiming 
         at racial bias mitigation</b>. Accordingly, we propose a racist hate speech detection framework, which includes a new method that embodies explicit and implicit 
         contextual information. The proposed method overcame literature baselines and it is the current state-of-the-art for Portuguese. 
         Furthermore, the <b>first large-scale expert annotated corpus for Brazilian hate speech detection</b> and a <b>specialized lexicon</b> were also proposed. 
         The <A HREF="#1">HateBR corpus</A> was collected from the comment section of Brazilian politicians' accounts on Instagram and manually annotated by specialists. It is composed of 
         7,000 documents annotated according to three different layers: a binary classification (offensive versus non-offensive comments), 
         offensiveness-level classification (highly, moderately, and slightly offensive), and nine hate speech groups 
         (xenophobia, racism, homophobia, sexism, religious intolerance, partyism, apology for the dictatorship, antisemitism, and fatphobia).
         The proposed specialized lexicon titled <A HREF="#1">MOL - Mutilingual Offensive Lexicon</A>  was manually identified by a linguist from the proposed corpus, which holds 1,000 explicit and implicit 
         pejorative terms and expressions annotated with contextual information. Both the corpus and the contextual-aware offensive lexicon were 
         annotated by three different experts and achieved high inter-annotator agreement. <b>Future research exploration involves new experiments using 
         large-scale language models, expansion and improvements of the proposed resources, and investigating metrics to evaluate racial bias 
         in hate speech detection systems </b>.
         
      </p>
 
 <div>      
      <p align="justify">
      <h6><b>Team</b></h6>
        <ul>
          <li><a href="https://github.com/franciellevargas">Francielle Vargas</a>. University of São Paulo, Brazil
          <li><a href="https://www.linkedin.com/in/isabelle--carvalho/">Isabelle Carvalho</a>. University of São Paulo, Brazil
          <li><a href="https://www.linkedin.com/in/fabianargoes/">Fabiana Goés</a>. University of São Paulo, Brazil
          <li><a href="https://homepages.dcc.ufmg.br/~fabricio/">Fabrício Benevenuto</a>. Federal University of Minas Gerais, Brazil
          <li><a href="https://sites.icmc.usp.br/taspardo/">Thiago Pardo</a>. University of São Paulo, Brazil
          <li><a href="https://departament-filcat-linguistica.ub.edu/directori-organitzatiu/wolfgang-sebastian-schmeisser-nieto">Wolfgang Schmeisser</a>. University of Barcelona, Spain
          <li><a href="https://www.linkedin.com/in/mohamed-diallo-33387058//"> Diallo Mohamed</a>. Université Saint-Thomas d'Aquin, Burkina Faso-Africa
          <li><a href="https://www.linkedin.com/in/zohar-rabinovich/"> Zohar Rabinovich</a>. University of Southern California, United States
          <li><a href="https://www.linkedin.com/in/mailaucq/"> Laura Quispe</a>. Universidad Nacional de San Agustin de Arequipa, Peru
          <li><a href="http://www.hurrial.com/"> Ali Hürriyetoğlu</a>. Royal Netherlands Academy of Arts and Sciences, Netherlands
        </ul>
 </div> 


<hr>       
</hr>

  </p>

<!-- Publications --> 
    <h3><A NAME = "1"><b>Publications</b></h3> 
    <ol>
    <ul>
      <li>
        <b>Vargas, F. </b>, Carvalho, I., Góes, F.R., Pardo, T.A.S., Benevenuto, F. (2022). <b> BrazilNoHate: Explicit and Implicit Offensiveness Detection Towards Bias
Mitigating in Brazilian Portuguese.</b> 17th Conference of the European Chapter of the Association for Computational Linguistics - System Demonstrations (EACL). pp.1‑6. Dubrovnik, Croatia.
        <a href="https://2023.eacl.org/">submitted</a>
        <!-- 
         -->
      </li>
    </ul>
    </ol>
       
    <ol>
    <ul>
      <li>
        <b>Vargas, F. </b>, Carvalho, I., Góes, F.R., Pardo, T.A.S., Benevenuto, F. (2022). <b> Contextual-aware and expert resources for Brazilian Portuguese hate speech detection.</b> 
        Natural Language Engineering Journal. pp.1-26. 
        [<a href="https://favargas.files.wordpress.com/2022/09/nle-v2.pdf">submitted</a>]
        <!-- 
         -->
      </li>
    </ul>
    </ol>
       
    <ol>
    <ul>
      <li>
        <b>Vargas, F. </b>, Carvalho, I., Góes, F.R., Pardo, T.A.S., Benevenuto, F. (2022). <b> HateBR: A large expert annotated corpus of Brazilian Instagram comments for offensive language and hate speech detection.</b>
        13th Conference on Language Resources and Evaluation (LREC). pp.7174–7183. Marseille, France.
        [<a href="http://www.lrec-conf.org/proceedings/lrec2022/pdf/2022.lrec-1.777.pdf">pdf</a>]
        <!-- 
         -->
      </li>
    </ul>
    </ol>
    
   <ol>
    <ul>
      <li>
        Machado, M. T., Pardo, T. A. S., Ruiz, E. E. S., Di Felippo, A., <b>Vargas, F. </b> (2022). <b> Implicit opinion aspect clues in Portuguese texts: analysis and categorization.</b>
        15th International Conference on Computational Processing of Portuguese (PROPOR). pp.68-78. Fortaleza, Brazil.
        [<a href="https://link.springer.com/chapter/10.1007/978-3-030-98305-5_7">pdf</a>]
        <!-- 
         -->
      </li>
    </ul>
    </ol>

    <ol>
    <ul>
      <li>
        <b>Vargas, F. </b>, Góes, F.R., Carvalho, I., Pardo, T.A.S., Benevenuto, F. (2021). <b> Contextual-lexicon approach for abusive language detection</b>.
        International Conference Recent Advances in Natural Language Processing - Deep Learning for Natural Language Processing Methods and Applications (RANLP). pp.1442-1451. Held Online.
        [<a href="https://aclanthology.org/2021.ranlp-1.161/">pdf</a>]
        <!-- 
         -->
      </li>
    </ul>
    </ol> 

 <ol>
    <ul>
      <li>
        <b>Vargas, F. </b>, Pardo, T.A.S. (2020). <b> Linguistic rules for fine-grained opinion extraction.</b>
        5th International Workshop on Social Sensing: Special Edition on Narrative Analysis on Social Media. Workshop Proceedings of the 14th International AAAI Conference on Web and Social Media (ICWSM). pp.1-6. Held Online.
        [<a href="http://workshop-proceedings.icwsm.org/abstract?id=2020_24">pdf</a>]
        <!-- 
         -->
      </li>
    </ul>
    </ol>
<hr>       
</hr>  
   
<div>  
<!-- Resources --> 
<h3><A NAME = "2"><b>Resources</b></h3> 
     <h6>Datasets</h6>
        <ul>
          <li><a href="https://github.com/franciellevargas/HateBR">HateBR</a>: Large-scale expert annotated corpus of Brazilian Instagram comments for abusive language detection.
        </ul>
            
    <h6>Lexicon</h6>
        <ul>
          <li><a href="https://github.com/franciellevargas/MOL">MOL<a/>: Multilingual offensive lexicon annotated with contextual information.
        </ul>
</div>
   
<hr>       
</hr>

<div>
   <!-- Sponsorship --> 
   <h3><A NAME = "3"><b>Sponsorship</b></h3> 
   <img src="fapesp.jpg">
   <img src="fapemg.png">
   <img src="locus_media.png">
   <img src="cnpq-capes.png">
   <img src="sinch-logo.png">
</div>

 </article>
<!-- Footer -->    
<footer class="sticky-bottom mt-5">
  <div class="container">
    &copy; Copyright 2021 Francielle Vargas.
    Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.  
  </div>
</footer>

  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
